{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature and Rainfall Analysis using PyCaret - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Merging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:41:42.117223600Z",
     "start_time": "2023-06-14T20:41:42.085147Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# temperature_df = pd.read_excel('dataset/Temp_SRS_1Jan1964_to_31Oct2020.xlsx')\n",
    "# rainfall_df = pd.read_csv('dataset/Rainfall_at_SRS_30Nov1960_to_18Nov2020.csv')\n",
    "#\n",
    "# rainfall_df = rainfall_df.fillna(0)\n",
    "#\n",
    "# temperature_df['DATE'] = pd.to_datetime(temperature_df['DATE'], format='%Y-%m-%d')\n",
    "# rainfall_df['DATE'] = pd.to_datetime(rainfall_df['DATE'], format='%m/%d/%Y')\n",
    "#\n",
    "# temperature_df['YEAR'] = pd.to_datetime(temperature_df.DATE).dt.year\n",
    "# rainfall_df['YEAR'] = pd.to_datetime(rainfall_df.DATE).dt.year\n",
    "#\n",
    "# temperature_df_grouped = temperature_df.groupby('YEAR').agg({'LOW TEMP': 'mean', 'HIGH TEMP': 'mean'})\n",
    "# temperature_df_grouped['RAINFALL'] = rainfall_df.groupby('YEAR').agg({'200-F Rainfall (inches/day)': 'mean'})\n",
    "# rain_temp_df = pd.merge(temperature_df, rainfall_df, on='DATE')\n",
    "# temperature_df_grouped.reset_index(inplace=True)\n",
    "# temperature_df_grouped.head()\n",
    "# # print(rain_temp_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting rainfall using average yearly maximum and minimum temperatures using LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# from pycaret.time_series import *\n",
    "#\n",
    "# train_df = temperature_df_grouped.query('YEAR < 2010')\n",
    "# test_df = temperature_df_grouped.query('YEAR >= 2010')\n",
    "#\n",
    "# reg = setup(data=train_df, target='RAINFALL')\n",
    "#\n",
    "# model = models()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:41:42.163410700Z",
     "start_time": "2023-06-14T20:41:42.117223600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "            DATE  MIN_TEMP  MAX_TEMP  RAINFALL  POPULATION\n5737  1979-09-17      61.0      70.0      0.05         1.0\n5738  1979-09-18      64.0      74.0      0.07         0.0\n5739  1979-09-19      64.0      83.0      0.03         0.0\n5740  1979-09-20      62.0      78.0      0.02         1.0\n5741  1979-09-21      71.0      81.0      0.19         0.0\n...          ...       ...       ...       ...         ...\n20753 2020-10-27      62.0      81.0      0.00         0.0\n20754 2020-10-28      69.0      85.0      0.00         0.0\n20755 2020-10-29      66.0      84.0      0.01         0.0\n20756 2020-10-30      50.0      73.0      0.03         0.0\n20757 2020-10-31      47.0      64.0      0.00         0.0\n\n[15021 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>MIN_TEMP</th>\n      <th>MAX_TEMP</th>\n      <th>RAINFALL</th>\n      <th>POPULATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5737</th>\n      <td>1979-09-17</td>\n      <td>61.0</td>\n      <td>70.0</td>\n      <td>0.05</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5738</th>\n      <td>1979-09-18</td>\n      <td>64.0</td>\n      <td>74.0</td>\n      <td>0.07</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5739</th>\n      <td>1979-09-19</td>\n      <td>64.0</td>\n      <td>83.0</td>\n      <td>0.03</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5740</th>\n      <td>1979-09-20</td>\n      <td>62.0</td>\n      <td>78.0</td>\n      <td>0.02</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5741</th>\n      <td>1979-09-21</td>\n      <td>71.0</td>\n      <td>81.0</td>\n      <td>0.19</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20753</th>\n      <td>2020-10-27</td>\n      <td>62.0</td>\n      <td>81.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20754</th>\n      <td>2020-10-28</td>\n      <td>69.0</td>\n      <td>85.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20755</th>\n      <td>2020-10-29</td>\n      <td>66.0</td>\n      <td>84.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20756</th>\n      <td>2020-10-30</td>\n      <td>50.0</td>\n      <td>73.0</td>\n      <td>0.03</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20757</th>\n      <td>2020-10-31</td>\n      <td>47.0</td>\n      <td>64.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15021 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temperature_df = pd.read_excel('dataset/Temp_SRS_1Jan1964_to_31Oct2020.xlsx')\n",
    "rainfall_df = pd.read_csv('dataset/Rainfall_at_SRS_30Nov1960_to_18Nov2020.csv')\n",
    "salamander_df = pd.read_excel('dataset/RB-GBdataForAImodel.xlsx')\n",
    "\n",
    "salamander_df['Date'] = salamander_df['Date'].astype(str)\n",
    "salamander_df.loc[salamander_df['Date'].str.startswith('1'), 'Date'] = salamander_df['Date'].str.replace('1', '20', 1)\n",
    "salamander_df.loc[~salamander_df['Date'].str.startswith('20'), 'Date'] = '19' + salamander_df['Date']\n",
    "salamander_df = salamander_df.rename(columns={'Date': 'DATE'})\n",
    "salamander_df = salamander_df.query(\"Site == 'RB'\")\n",
    "salamander_df.head()\n",
    "\n",
    "rainfall_df = rainfall_df.fillna(0)\n",
    "\n",
    "temperature_df['DATE'] = pd.to_datetime(temperature_df['DATE'], format='%Y-%m-%d')\n",
    "rainfall_df['DATE'] = pd.to_datetime(rainfall_df['DATE'], format='%m/%d/%Y')\n",
    "salamander_df['DATE'] = pd.to_datetime(salamander_df['DATE'], format='%Y%m%d')\n",
    "\n",
    "total_salamander_pop_df = salamander_df.groupby(salamander_df['DATE'].dt.date)[\"Number\"].sum().reset_index()\n",
    "total_salamander_pop_df.DATE = pd.to_datetime(total_salamander_pop_df.DATE, format='%Y-%m-%d')\n",
    "total_salamander_pop_df.head()\n",
    "\n",
    "rain_temp_df = pd.merge(temperature_df, rainfall_df, on='DATE', how=\"outer\")\n",
    "rain_temp_salamander_df = pd.merge(rain_temp_df, total_salamander_pop_df, on='DATE', how=\"outer\")\n",
    "rain_temp_salamander_df = rain_temp_salamander_df.rename(columns={'LOW TEMP': 'MIN_TEMP', 'HIGH TEMP': 'MAX_TEMP', '200-F Rainfall (inches/day)': 'RAINFALL', 'Number': 'POPULATION'})\n",
    "start_date = '1979-09-17'\n",
    "end_date = '2020-10-31'\n",
    "rain_temp_salamander_df = rain_temp_salamander_df.query(\"DATE >= @start_date and DATE <= @end_date\")\n",
    "# the dates above are selected because salamander data are available only from 1979-09-17 and the temperature data are available only till 2020-10-31\n",
    "rain_temp_salamander_df['POPULATION'].fillna(0, inplace=True)\n",
    "rain_temp_salamander_df['RAINFALL'].fillna(0, inplace=True)\n",
    "rain_temp_salamander_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:41:43.691912300Z",
     "start_time": "2023-06-14T20:41:42.121797Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation for passing to LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "#\n",
    "# rainfall_data = rainfall_df.values\n",
    "# sequence_length = 80\n",
    "# no_of_features = 1\n",
    "#\n",
    "# samples = list()\n",
    "# for i in range(0, len(rainfall_data), sequence_length):\n",
    "#     sample = rainfall_data[i:i+sequence_length]\n",
    "#     if len(sample) == sequence_length:\n",
    "#         samples.append(sample)\n",
    "#\n",
    "# samples = np.array(samples)\n",
    "# samples = samples.reshape(len(samples), sequence_length, no_of_features)\n",
    "#\n",
    "# train_size = 80 # int(len(samples) * 0.8)\n",
    "# train, val = samples[:train_size], samples[train_size:]\n",
    "#\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# train = scaler.fit_transform(train.reshape(-1, no_of_features)).reshape(train.shape)\n",
    "# val = scaler.transform(val.reshape(-1, no_of_features)).reshape(val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:41:43.711603600Z",
     "start_time": "2023-06-14T20:41:43.691912300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "#\n",
    "# lstm = nn.LSTM(input_size=1, hidden_size=10) # input size is 1 because the input is rainfall level only\n",
    "#\n",
    "# input_data = train[:, :, 0] # input shape is (80, 60), sequence length is 60, batch size is 80, input size is 1\n",
    "# input_data = torch.from_numpy(input_data)\n",
    "# input_data = input_data.to(torch.float32) # casted to float32 because the extra dimension step encounters data type error\n",
    "# output_data = train[:, -1, 0] # output shape is (80), output size is 1\n",
    "#\n",
    "# hidden = torch.zeros(1, 80, 10) # hidden state shape is (1, 80, 10), num_layers is 1, num_directions is 1, batch size is 80, hidden size is 10\n",
    "# cell = torch.zeros(1, 80, 10) # cell state shape is (1, 80, 10), same as hidden state\n",
    "#\n",
    "# out, (hidden, cell) = lstm(input_data.unsqueeze(-1), (hidden, cell)) # adds an extra dimension for the input size\n",
    "#\n",
    "# linear = nn.Linear(10, 1)\n",
    "# prediction = linear(out[-1]) # take the last output of the sequence and pass it to the linear layer\n",
    "#\n",
    "# print(prediction)\n",
    "# print(output_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:41:43.816952300Z",
     "start_time": "2023-06-14T20:41:43.711603600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/300 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d044df6b713240b39db313f7db87f545"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 121\u001B[0m\n\u001B[0;32m    119\u001B[0m criterion \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[0;32m    120\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[1;32m--> 121\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensorboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[49], line 97\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, criterion, optimizer, tensorboard, num_epochs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloaders[phase]):\n\u001B[0;32m     96\u001B[0m     X_batch, y_batch \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m---> 97\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(y_pred\u001B[38;5;241m.\u001B[39msqueeze(), y_batch)\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m phase \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\denv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[49], line 72\u001B[0m, in \u001B[0;36mLSTMModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     69\u001B[0m c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Pass the input through the LSTM layer\u001B[39;00m\n\u001B[1;32m---> 72\u001B[0m out, (hn, cn) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m hn \u001B[38;5;241m=\u001B[39m hn\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# Pass the last output of the LSTM layer through the linear layer\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# out = self.fc(out[:, -1, :])\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\denv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\denv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 812\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    813\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    815\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    816\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define the hyperparameters\n",
    "input_size = 4 # The number of features in the input\n",
    "hidden_size = 32 # The number of hidden units in the LSTM\n",
    "num_layers = 8 # The number of LSTM layers\n",
    "output_size = 1 # The number of features in the output\n",
    "batch_size = 32 # The size of each batch of data\n",
    "num_epochs = 300 # The number of epochs to train the model\n",
    "learning_rate = 0.001 # The learning rate for the optimizer\n",
    "\n",
    "# Define a custom dataset class to load the sequences into PyTorch tensors\n",
    "class RainTempSalamanderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        df = df.drop(\"DATE\", axis=1)\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(df[[\"MIN_TEMP\", \"MAX_TEMP\", \"RAINFALL\", \"POPULATION\"]].values[:-1])\n",
    "        y = df[\"POPULATION\"].values[1:]\n",
    "        self.X = torch.tensor(X, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_df, test_df = train_test_split(rain_temp_salamander_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = RainTempSalamanderDataset(train_df)\n",
    "test_dataset = RainTempSalamanderDataset(test_df)\n",
    "\n",
    "# Create train and test datasets using the custom dataset class\n",
    "datasets = {\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "}\n",
    "\n",
    "# Create train and test dataloaders using the datasets\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(datasets['train'], batch_size=batch_size, shuffle=False),\n",
    "    'test': torch.utils.data.DataLoader(datasets['test'], batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(hidden_size, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize the hidden and cell states with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "\n",
    "        # Pass the input through the LSTM layer\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_model(model, criterion, optimizer, tensorboard, num_epochs = 3):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_mae = 0.0\n",
    "            running_rmse = 0.0\n",
    "\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                X_batch, y_batch = data\n",
    "                y_pred = model(X_batch.unsqueeze(1))\n",
    "                loss = criterion(y_pred.squeeze(), y_batch)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "                running_mae += torch.abs(y_pred.squeeze() - y_batch).sum().item()\n",
    "                running_rmse += torch.sqrt(torch.pow(y_pred.squeeze() - y_batch, 2).sum()).item()\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_mae = running_mae / len(datasets[phase])\n",
    "            epoch_rmse = running_rmse / len(datasets[phase])\n",
    "\n",
    "            tensorboard.add_scalar(f\"Loss during {phase}\", epoch_loss, epoch)\n",
    "            tensorboard.add_scalar(f\"MAE during {phase}\", epoch_mae, epoch)\n",
    "            tensorboard.add_scalar(f\"RMSE during {phase}\", epoch_rmse, epoch)\n",
    "    tensorboard.close()\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "tensorboard = SummaryWriter()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_model(model, criterion, optimizer, tensorboard, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:54:53.737097600Z",
     "start_time": "2023-06-14T20:41:43.751505200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
