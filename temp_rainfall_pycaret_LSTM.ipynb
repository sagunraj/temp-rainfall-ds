{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature and Rainfall Analysis using PyCaret - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Merging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T20:20:54.099044Z",
     "start_time": "2023-06-01T20:20:54.096138Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# temperature_df = pd.read_excel('dataset/Temp_SRS_1Jan1964_to_31Oct2020.xlsx')\n",
    "# rainfall_df = pd.read_csv('dataset/Rainfall_at_SRS_30Nov1960_to_18Nov2020.csv')\n",
    "#\n",
    "# rainfall_df = rainfall_df.fillna(0)\n",
    "#\n",
    "# temperature_df['DATE'] = pd.to_datetime(temperature_df['DATE'], format='%Y-%m-%d')\n",
    "# rainfall_df['DATE'] = pd.to_datetime(rainfall_df['DATE'], format='%m/%d/%Y')\n",
    "#\n",
    "# temperature_df['YEAR'] = pd.to_datetime(temperature_df.DATE).dt.year\n",
    "# rainfall_df['YEAR'] = pd.to_datetime(rainfall_df.DATE).dt.year\n",
    "#\n",
    "# temperature_df_grouped = temperature_df.groupby('YEAR').agg({'LOW TEMP': 'mean', 'HIGH TEMP': 'mean'})\n",
    "# temperature_df_grouped['RAINFALL'] = rainfall_df.groupby('YEAR').agg({'200-F Rainfall (inches/day)': 'mean'})\n",
    "# rain_temp_df = pd.merge(temperature_df, rainfall_df, on='DATE')\n",
    "# temperature_df_grouped.reset_index(inplace=True)\n",
    "# temperature_df_grouped.head()\n",
    "# # print(rain_temp_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting rainfall using average yearly maximum and minimum temperatures using LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from pycaret.time_series import *\n",
    "#\n",
    "# train_df = temperature_df_grouped.query('YEAR < 2010')\n",
    "# test_df = temperature_df_grouped.query('YEAR >= 2010')\n",
    "#\n",
    "# reg = setup(data=train_df, target='RAINFALL')\n",
    "#\n",
    "# model = models()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T20:20:54.101702Z",
     "start_time": "2023-06-01T20:20:54.099948Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   RAINFALL\n0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RAINFALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rainfall_df = pd.read_csv('dataset/Rainfall_at_SRS_30Nov1960_to_18Nov2020.csv')\n",
    "rainfall_df = rainfall_df.fillna(0)\n",
    "rainfall_df.rename(columns={'200-F Rainfall (inches/day)': 'RAINFALL'}, inplace=True)\n",
    "rainfall_df = rainfall_df.drop(columns={'DATE'})\n",
    "\n",
    "rainfall_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T20:20:54.391112Z",
     "start_time": "2023-06-01T20:20:54.102003Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation for passing to LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "#\n",
    "# rainfall_data = rainfall_df.values\n",
    "# sequence_length = 80\n",
    "# no_of_features = 1\n",
    "#\n",
    "# samples = list()\n",
    "# for i in range(0, len(rainfall_data), sequence_length):\n",
    "#     sample = rainfall_data[i:i+sequence_length]\n",
    "#     if len(sample) == sequence_length:\n",
    "#         samples.append(sample)\n",
    "#\n",
    "# samples = np.array(samples)\n",
    "# samples = samples.reshape(len(samples), sequence_length, no_of_features)\n",
    "#\n",
    "# train_size = 80 # int(len(samples) * 0.8)\n",
    "# train, val = samples[:train_size], samples[train_size:]\n",
    "#\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# train = scaler.fit_transform(train.reshape(-1, no_of_features)).reshape(train.shape)\n",
    "# val = scaler.transform(val.reshape(-1, no_of_features)).reshape(val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T20:20:54.396095Z",
     "start_time": "2023-06-01T20:20:54.394171Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "#\n",
    "# lstm = nn.LSTM(input_size=1, hidden_size=10) # input size is 1 because the input is rainfall level only\n",
    "#\n",
    "# input_data = train[:, :, 0] # input shape is (80, 60), sequence length is 60, batch size is 80, input size is 1\n",
    "# input_data = torch.from_numpy(input_data)\n",
    "# input_data = input_data.to(torch.float32) # casted to float32 because the extra dimension step encounters data type error\n",
    "# output_data = train[:, -1, 0] # output shape is (80), output size is 1\n",
    "#\n",
    "# hidden = torch.zeros(1, 80, 10) # hidden state shape is (1, 80, 10), num_layers is 1, num_directions is 1, batch size is 80, hidden size is 10\n",
    "# cell = torch.zeros(1, 80, 10) # cell state shape is (1, 80, 10), same as hidden state\n",
    "#\n",
    "# out, (hidden, cell) = lstm(input_data.unsqueeze(-1), (hidden, cell)) # adds an extra dimension for the input size\n",
    "#\n",
    "# linear = nn.Linear(10, 1)\n",
    "# prediction = linear(out[-1]) # take the last output of the sequence and pass it to the linear layer\n",
    "#\n",
    "# print(prediction)\n",
    "# print(output_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T20:20:54.400100Z",
     "start_time": "2023-06-01T20:20:54.398150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8a927709b844687b65534ea8af915f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define the hyperparameters\n",
    "input_size = 1 # The number of features in the input\n",
    "hidden_size = 32 # The number of hidden units in the LSTM\n",
    "num_layers = 2 # The number of LSTM layers\n",
    "output_size = 1 # The number of features in the output\n",
    "batch_size = 16 # The size of each batch of data\n",
    "num_epochs = 20 # The number of epochs to train the model\n",
    "learning_rate = 0.0001 # The learning rate for the optimizer\n",
    "\n",
    "# Convert the dataframe to a numpy array and normalize the rainfall values\n",
    "data = rainfall_df.values.astype(float)\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "train_size = int(len(data) * 0.8)\n",
    "test_size = len(data) - train_size\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "# Define a function to create sequences of data with a given window size\n",
    "def create_sequences(data, window_size):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        seq = data[i:i+window_size+1]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Create sequences of data with a window size of 12 (one year)\n",
    "window_size = 12\n",
    "train_sequences = create_sequences(train_data, window_size)\n",
    "test_sequences = create_sequences(test_data, window_size)\n",
    "\n",
    "# Define a custom dataset class to load the sequences into PyTorch tensors\n",
    "class RainfallDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq = self.sequences[index]\n",
    "        x = torch.tensor(seq[:-1], dtype=torch.float32).unsqueeze(-1) # The input is the sequence except the last element\n",
    "        y = torch.tensor(seq[-1], dtype=torch.float32).unsqueeze(-1) # The output is the last element of the sequence\n",
    "        x = x.squeeze(-1)\n",
    "        y = y.squeeze(-1)\n",
    "        return x, y\n",
    "\n",
    "# Create train and test datasets using the custom dataset class\n",
    "datasets = {\n",
    "    'train': RainfallDataset(train_sequences),\n",
    "    'test': RainfallDataset(test_sequences)\n",
    "}\n",
    "\n",
    "# Create train and test dataloaders using the datasets\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(datasets['test'], batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) # The LSTM layer\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size) # The linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize the hidden and cell states with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "\n",
    "        # Pass the input through the LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Pass the last output of the LSTM layer through the linear layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_model(model, criterion, optimizer, tensorboard, num_epochs = 3):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                x_batch, y_batch = data\n",
    "                y_pred = model(x_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(y_pred, 1)\n",
    "                running_loss += loss.detach() * x_batch.size(0)\n",
    "                running_corrects += torch.sum(preds == y_batch.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_acc = running_corrects.float() / len(datasets[phase])\n",
    "\n",
    "            tensorboard.add_scalar(f\"Loss during {phase}\", epoch_loss, epoch)\n",
    "            tensorboard.add_scalar(f\"Accuracy during {phase}\", epoch_acc, epoch)\n",
    "    tensorboard.close()\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "tensorboard = SummaryWriter()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_model(model, criterion, optimizer, tensorboard, 40)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "#     # Set the model to training mode\n",
    "#     model.train()\n",
    "#     # Loop over the batches of data in the train dataloader\n",
    "#     for x_batch, y_batch in train_dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         y_pred = model(x_batch)\n",
    "#         loss = criterion(y_pred, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#     # Print the loss every 10 epochs\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "#\n",
    "# # Evaluate the model\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "#\n",
    "# # Initialize the lists to store the predictions and the actual values\n",
    "# predictions = []\n",
    "# actuals = []\n",
    "#\n",
    "# # Loop over the batches of data in the test dataloader\n",
    "# with torch.no_grad():\n",
    "#     for x_batch, y_batch in test_dataloader:\n",
    "#         # Forward pass\n",
    "#         y_pred = model(x_batch)\n",
    "#\n",
    "#         # Append the predictions and the actual values to the lists\n",
    "#         predictions.extend(y_pred.squeeze().tolist())\n",
    "#         actuals.extend(y_batch.squeeze().tolist())\n",
    "#\n",
    "# # Compute the root mean squared error (RMSE) between the predictions and the actual values\n",
    "# rmse = np.sqrt(np.mean((np.array(predictions) - np.array(actuals))**2))\n",
    "# print(f'RMSE: {rmse:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T20:23:02.316233Z",
     "start_time": "2023-06-01T20:20:54.409701Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
